import csv
from faker import Faker
import random
from datetime import datetime, timedelta

# Initialize Faker
fake = Faker()

# Define the number of records and columns
num_records = 200000
num_columns = 30

# Define generic column types
column_types = [
    'text', 'number', 'date', 'boolean', 'category',
    'id', 'code', 'percentage', 'rating', 'status'
]

# Extend the list to have at least 30 items
while len(column_types) < num_columns:
    column_types.extend(column_types)
column_types = column_types[:num_columns]

def generate_fake_data(data_type):
    if data_type == 'text':
        return fake.text(max_nb_chars=50).replace('\n', ' ').replace('\r', '')
    elif data_type == 'number':
        return str(random.randint(1, 1000000))
    elif data_type == 'date':
        return fake.date_between(start_date='-30y', end_date='today').isoformat()
    elif data_type == 'boolean':
        return str(random.choice([True, False]))
    elif data_type == 'category':
        return fake.word()
    elif data_type == 'id':
        return fake.uuid4()
    elif data_type == 'code':
        return fake.bothify(text='??##??##', letters='ABCDEFGHIJKLMNOPQRSTUVWXYZ')
    elif data_type == 'percentage':
        return f"{random.uniform(0, 100):.2f}%"
    elif data_type == 'rating':
        return str(random.randint(1, 5))
    elif data_type == 'status':
        return random.choice(['Active', 'Inactive', 'Pending', 'Completed', 'Cancelled'])
    else:
        return fake.word()

# Generate and write data to a CSV file
output_file = 'generic_data.txt'

with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:
    writer = csv.writer(csvfile, delimiter='\t')
    
    # Write header with generic column names
    writer.writerow([f"Column_{i+1}" for i in range(num_columns)])
    
    # Write data rows
    for _ in range(num_records):
        row = [generate_fake_data(column_types[i]) for i in range(num_columns)]
        writer.writerow(row)

print(f"Generated {num_records} records with {num_columns} columns in {output_file}")
