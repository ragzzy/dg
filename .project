from pyspark.sql import SparkSession
from pyspark.sql.functions import monotonically_increasing_id, col

# Initialize Spark session
spark = SparkSession.builder.appName("AddRowNumber").getOrCreate()

# Read the file into a DataFrame
df = spark.read.csv('/path/to/your/file.csv', header=True, inferSchema=True)

# Add a monotonically increasing ID column
df_with_id = df.withColumn('id', monotonically_increasing_id())

# Get the number of partitions
num_partitions = df.rdd.getNumPartitions()

# Add a row number column by dividing the ID by the number of partitions
df_with_row_number = df_with_id.withColumn('row_number', (col('id') / num_partitions).cast('integer'))

# Show the DataFrame with the row number
df_with_row_number.show()

# Optionally, save the DataFrame with row numbers back to a file
df_with_row_number.write.csv('/path/to/save/with_row_numbers.csv', header=True)
