from pyspark.sql import SparkSession
from pyspark.sql.functions import monotonically_increasing_id, col, when

# Initialize Spark session
spark = SparkSession.builder.appName("RowLevelComparison").getOrCreate()

# Load the files into DataFrames
file1 = "path/to/first/file.csv"
file2 = "path/to/second/file.csv"

df1 = spark.read.csv(file1, header=True, inferSchema=True)
df2 = spark.read.csv(file2, header=True, inferSchema=True)

# Add row index to each DataFrame
df1 = df1.withColumn("row_index", monotonically_increasing_id())
df2 = df2.withColumn("row_index", monotonically_increasing_id())

# Join the DataFrames on the row index
joined_df = df1.join(df2, df1.row_index == df2.row_index, "inner") \
               .select(df1["*"], df2["*"])

# Select the columns you want to compare
selected_columns = ["columnA", "columnB"]
for col in selected_columns:
    joined_df = joined_df.withColumnRenamed(f"{col}", f"{col}_file1") \
                         .withColumnRenamed(f"{col}_2", f"{col}_file2")

# Perform the comparison
comparison_df = joined_df.withColumn(
    "comparison_result",
    when(
        (col("columnA_file1") == col("columnA_file2")) & (col("columnB_file1") == col("columnB_file2")),
        "Match"
    ).otherwise("Mismatch")
)

# Show the result
comparison_df.select("row_index", "columnA_file1", "columnA_file2", "columnB_file1", "columnB_file2", "comparison_result").show()
