from databricks.sdk import WorkspaceClient
from datetime import datetime

def run_existing_job(
    job_id: int,
    parameters: dict = None,
    notebook_params: dict = None
) -> int:
    """
    Runs an existing Databricks job with specified parameters
    
    Args:
        job_id: ID of the existing job to run
        parameters: Dictionary of job-level parameters (if any)
        notebook_params: Dictionary of notebook parameters (if any)
    
    Returns:
        run_id: The ID of the job run
    """
    w = WorkspaceClient()
    
    try:
        # Run the job with parameters
        run_response = w.jobs.run_now(
            job_id=job_id,
            notebook_params=notebook_params,
            python_params=parameters
        )
        
        run_id = run_response.run_id
        print(f"Started job run {run_id} for job {job_id}")
        
        # Optionally get the run info
        run_info = w.jobs.get_run(run_id)
        print(f"Run status: {run_info.state.life_cycle_state}")
        
        return run_id
        
    except Exception as e:
        print(f"Error running job: {str(e)}")
        raise

def get_run_status(run_id: int) -> str:
    """
    Gets the current status of a job run
    
    Args:
        run_id: The ID of the job run to check
        
    Returns:
        status: Current status of the job run
    """
    w = WorkspaceClient()
    run_info = w.jobs.get_run(run_id)
    return run_info.state.life_cycle_state

def wait_for_job_completion(run_id: int, polling_interval: int = 30) -> dict:
    """
    Waits for a job to complete and returns the final status
    
    Args:
        run_id: The ID of the job run to monitor
        polling_interval: Number of seconds to wait between status checks
        
    Returns:
        dict: Final job status information
    """
    import time
    
    w = WorkspaceClient()
    while True:
        run_info = w.jobs.get_run(run_id)
        state = run_info.state.life_cycle_state
        
        print(f"Current job state: {state}")
        
        # Check if the job has finished (successfully or not)
        if state in ['TERMINATED', 'SKIPPED', 'INTERNAL_ERROR', 'FAILED']:
            return {
                'state': state,
                'result_state': run_info.state.result_state,
                'state_message': run_info.state.state_message
            }
            
        time.sleep(polling_interval)

# Example usage
if __name__ == "__main__":
    try:
        # Your existing job ID (you can find this in the URL when viewing the job)
        job_id = 123456
        
        # Example notebook parameters
        notebook_params = {
            "input_date": "2024-03-01",
            "environment": "production",
            "data_path": "/mnt/data/raw/"
        }
        
        # Run the job
        run_id = run_existing_job(
            job_id=job_id,
            notebook_params=notebook_params
        )
        
        # Optional: Wait for job completion and get final status
        final_status = wait_for_job_completion(run_id)
        print(f"Job finished with status: {final_status}")
        
    except Exception as e:
        print(f"Error in job execution process: {str(e)}")
