from faker import Faker
from azure.storage.blob import BlobServiceClient
import json
import random
import io
from reportlab.pdfgen import canvas
from datetime import datetime
import zipfile
import tempfile
import os

# Initialize Faker
fake = Faker()

# Azure Storage connection string - replace with your connection string
connection_string = "YOUR_CONNECTION_STRING"
container_name = "fake-files-container"

def create_fake_text():
    """Generate fake text content"""
    paragraphs = [fake.paragraph() for _ in range(random.randint(3, 10))]
    return "\n\n".join(paragraphs)

def create_fake_json():
    """Generate fake JSON content"""
    return {
        "id": fake.uuid4(),
        "title": fake.catch_phrase(),
        "description": fake.text(),
        "timestamp": str(fake.date_time_this_year()),
        "category": fake.word(),
        "tags": [fake.word() for _ in range(random.randint(2, 5))],
        "metadata": {
            "author": fake.company(),
            "version": f"{random.randint(1, 5)}.{random.randint(0, 9)}",
            "status": random.choice(["draft", "published", "archived"])
        }
    }

def create_fake_html():
    """Generate fake HTML content"""
    title = fake.catch_phrase()
    paragraphs = [fake.paragraph() for _ in range(random.randint(3, 7))]
    
    html_content = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>{title}</title>
    </head>
    <body>
        <h1>{title}</h1>
        {''.join([f'<p>{p}</p>' for p in paragraphs])}
    </body>
    </html>
    """
    return html_content

def create_fake_pdf():
    """Generate fake PDF content"""
    buffer = io.BytesIO()
    c = canvas.Canvas(buffer)
    
    # Add content to PDF
    c.drawString(100, 750, fake.catch_phrase())
    y_position = 700
    for _ in range(random.randint(3, 7)):
        text = fake.paragraph()
        # Split long text into multiple lines
        words = text.split()
        line = ""
        for word in words:
            if len(line + word) < 70:
                line += word + " "
            else:
                c.drawString(100, y_position, line)
                y_position -= 20
                line = word + " "
        if line:
            c.drawString(100, y_position, line)
            y_position -= 20
    
    c.save()
    buffer.seek(0)
    return buffer

def upload_files_to_blob(spark):
    """Main function to generate and upload files"""
    try:
        # Create blob service client
        blob_service_client = BlobServiceClient.from_connection_string(connection_string)
        
        # Create container if it doesn't exist
        try:
            container_client = blob_service_client.create_container(container_name)
        except:
            container_client = blob_service_client.get_container_client(container_name)
        
        # Create temporary directory for files
        temp_dir = tempfile.mkdtemp()
        zip_path = os.path.join(temp_dir, "fake_files.zip")
        
        # Create ZIP file
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            # Generate and upload files
            for i in range(100000):
                file_type = random.choice(['txt', 'json', 'html', 'pdf'])
                filename = f"fake_file_{i}.{file_type}"
                
                # Generate content based on file type
                if file_type == 'txt':
                    content = create_fake_text()
                    blob = content.encode('utf-8')
                elif file_type == 'json':
                    content = create_fake_json()
                    blob = json.dumps(content, indent=2).encode('utf-8')
                elif file_type == 'html':
                    content = create_fake_html()
                    blob = content.encode('utf-8')
                elif file_type == 'pdf':
                    blob = create_fake_pdf().getvalue()
                
                # Upload to blob storage
                blob_client = container_client.get_blob_client(filename)
                blob_client.upload_blob(blob, overwrite=True)
                
                # Add to ZIP file
                file_path = os.path.join(temp_dir, filename)
                with open(file_path, 'wb') as f:
                    f.write(blob)
                zipf.write(file_path, filename)
                os.remove(file_path)  # Clean up individual file
                
                # Log progress
                if (i + 1) % 1000 == 0:
                    print(f"Processed {i + 1} files")
        
        # Upload ZIP file to blob storage
        zip_blob_client = container_client.get_blob_client("fake_files.zip")
        with open(zip_path, 'rb') as zip_file:
            zip_blob_client.upload_blob(zip_file, overwrite=True)
        
        # Clean up temporary directory
        os.remove(zip_path)
        os.rmdir(temp_dir)
        
        print("File generation and upload completed successfully!")
        
    except Exception as e:
        print(f"An error occurred: {str(e)}")

# Execute the function
spark.sparkContext.parallelize([1]).foreach(lambda x: upload_files_to_blob(spark))
